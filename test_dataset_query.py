#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®é›†æŸ¥è¯¢åŠŸèƒ½éªŒè¯æµ‹è¯•

è¿™ä¸ªè„šæœ¬ç”¨äºéªŒè¯MCPæœåŠ¡å™¨çš„æ•°æ®é›†æŸ¥è¯¢åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
1. æ·»åŠ æµ‹è¯•æ•°æ®é›†
2. æµ‹è¯•æ•°æ®é›†æŸ¥è¯¢
3. æµ‹è¯•ç¡…åŸºæµåŠ¨APIé›†æˆ
4. éªŒè¯è‡ªç„¶è¯­è¨€æŸ¥è¯¢åŠŸèƒ½
"""

import asyncio
import json
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

try:
    from modelscope_mcp.core.config import Config
    from modelscope_mcp.services.database import DatabaseService
    from modelscope_mcp.services.cache import CacheService
    from modelscope_mcp.tools.list_datasets import ListDatasetsHandler
    from modelscope_mcp.tools.get_dataset_info import GetDatasetInfoHandler
    from modelscope_mcp.tools.query_dataset import QueryDatasetHandler
    from modelscope_mcp.models.dataset import Dataset
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)


class DatasetQueryTester:
    """æ•°æ®é›†æŸ¥è¯¢åŠŸèƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.config = None
        self.db_service = None
        self.cache_service = None
        self.handlers = {}
        self.test_datasets = []
    
    async def setup(self):
        """åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ"""
        try:
            print("ğŸ”§ åˆå§‹åŒ–æ•°æ®é›†æŸ¥è¯¢æµ‹è¯•ç¯å¢ƒ...")
            
            # åŠ è½½é…ç½®
            self.config = Config()
            print("âœ… é…ç½®åŠ è½½æˆåŠŸ")
            
            # åˆå§‹åŒ–æ•°æ®åº“æœåŠ¡
            self.db_service = DatabaseService(self.config)
            await self.db_service.initialize()
            print("âœ… æ•°æ®åº“æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–ç¼“å­˜æœåŠ¡
            self.cache_service = CacheService(self.config)
            await self.cache_service.initialize()
            print("âœ… ç¼“å­˜æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–å¤„ç†å™¨
            self.handlers = {
                'list_datasets': ListDatasetsHandler(self.db_service, self.cache_service),
                'get_dataset_info': GetDatasetInfoHandler(self.db_service, self.cache_service),
                'query_dataset': QueryDatasetHandler(self.db_service, self.cache_service)
            }
            print("âœ… å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            
            return True
            
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def add_test_datasets(self):
        """æ·»åŠ æµ‹è¯•æ•°æ®é›†"""
        print("\nğŸ“Š æ·»åŠ æµ‹è¯•æ•°æ®é›†...")
        
        test_datasets_data = [
            {
                "name": "chinese_text_classification",
                "display_name": "ä¸­æ–‡æ–‡æœ¬åˆ†ç±»æ•°æ®é›†",
                "description": "åŒ…å«æ–°é—»ã€è¯„è®ºç­‰å¤šç§ç±»å‹çš„ä¸­æ–‡æ–‡æœ¬åˆ†ç±»æ•°æ®",
                "source": "modelscope",
                "source_id": "damo/nlp_structbert_sentiment-classification_chinese-base",
                "category": "text-classification",
                "tags": ["ä¸­æ–‡", "æ–‡æœ¬åˆ†ç±»", "æƒ…æ„Ÿåˆ†æ"],
                "total_samples": 10000,
                "size_bytes": 50000000
            },
            {
                "name": "english_sentiment_analysis",
                "display_name": "è‹±æ–‡æƒ…æ„Ÿåˆ†ææ•°æ®é›†",
                "description": "è‹±æ–‡ç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†ææ•°æ®é›†",
                "source": "huggingface",
                "source_id": "imdb",
                "category": "text-classification",
                "tags": ["è‹±æ–‡", "æƒ…æ„Ÿåˆ†æ", "ç”µå½±è¯„è®º"],
                "total_samples": 50000,
                "size_bytes": 100000000
            },
            {
                "name": "chinese_ner_dataset",
                "display_name": "ä¸­æ–‡å‘½åå®ä½“è¯†åˆ«æ•°æ®é›†",
                "description": "ä¸­æ–‡å‘½åå®ä½“è¯†åˆ«æ ‡æ³¨æ•°æ®",
                "source": "modelscope",
                "source_id": "damo/nlp_structbert_named-entity-recognition_chinese-base",
                "category": "token-classification",
                "tags": ["ä¸­æ–‡", "å‘½åå®ä½“è¯†åˆ«", "NER"],
                "total_samples": 8000,
                "size_bytes": 30000000
            }
        ]
        
        try:
            for dataset_data in test_datasets_data:
                # åˆ›å»ºæ•°æ®é›†å¯¹è±¡
                dataset = Dataset(
                    name=dataset_data["name"],
                    display_name=dataset_data["display_name"],
                    description=dataset_data["description"],
                    source=dataset_data["source"],
                    source_id=dataset_data["source_id"],
                    category=dataset_data["category"],
                    tags=dataset_data["tags"],
                    total_samples=dataset_data["total_samples"],
                    size_bytes=dataset_data["size_bytes"],
                    created_at=datetime.now()
                )
                
                # ä¿å­˜åˆ°æ•°æ®åº“
                dataset_dict = {
                    "name": dataset.name,
                    "display_name": dataset.display_name,
                    "description": dataset.description,
                    "source": dataset.source,
                    "source_id": dataset.source_id,
                    "category": dataset.category,
                    "tags": dataset.tags,
                    "total_samples": dataset.total_samples,
                    "size_bytes": dataset.size_bytes,
                    "created_at": dataset.created_at
                }
                created_dataset = await self.db_service.create_dataset(dataset_dict)
                self.test_datasets.append(created_dataset)
                print(f"âœ… æ·»åŠ æ•°æ®é›†: {created_dataset.display_name}")
            
            print(f"ğŸ“Š æˆåŠŸæ·»åŠ  {len(self.test_datasets)} ä¸ªæµ‹è¯•æ•°æ®é›†")
            return True
            
        except Exception as e:
            print(f"âŒ æ·»åŠ æµ‹è¯•æ•°æ®é›†å¤±è´¥: {e}")
            return False
    
    async def test_list_datasets(self):
        """æµ‹è¯•åˆ—å‡ºæ•°æ®é›†åŠŸèƒ½"""
        print("\nğŸ” æµ‹è¯•åˆ—å‡ºæ•°æ®é›†åŠŸèƒ½...")
        
        test_cases = [
            {"name": "åˆ—å‡ºæ‰€æœ‰æ•°æ®é›†", "args": {}},
            {"name": "æŒ‰åˆ†ç±»ç­›é€‰", "args": {"category": "text-classification"}},
            {"name": "æŒ‰æ¥æºç­›é€‰", "args": {"source": "modelscope"}},
            {"name": "æœç´¢å…³é”®è¯", "args": {"search": "ä¸­æ–‡"}}
        ]
        
        results = []
        
        for test_case in test_cases:
            try:
                result = await self.handlers['list_datasets'].handle(test_case["args"])
                success = result.get("success", False)
                count = len(result.get("datasets", []))
                
                print(f"  {test_case['name']}: {'âœ…' if success else 'âŒ'} ({count} ä¸ªæ•°æ®é›†)")
                results.append(success)
                
            except Exception as e:
                print(f"  {test_case['name']}: âŒ é”™è¯¯: {e}")
                results.append(False)
        
        return all(results)
    
    async def test_dataset_info(self):
        """æµ‹è¯•è·å–æ•°æ®é›†ä¿¡æ¯åŠŸèƒ½"""
        print("\nğŸ” æµ‹è¯•è·å–æ•°æ®é›†ä¿¡æ¯åŠŸèƒ½...")
        
        if not self.test_datasets:
            print("âŒ æ²¡æœ‰æµ‹è¯•æ•°æ®é›†")
            return False
        
        try:
            # æµ‹è¯•è·å–ç¬¬ä¸€ä¸ªæ•°æ®é›†çš„ä¿¡æ¯
            dataset = self.test_datasets[0]
            result = await self.handlers['get_dataset_info'].handle({
                "dataset_name": dataset.name
            })
            
            success = result.get("success", False)
            dataset_info = result.get("dataset")
            
            if success and dataset_info:
                print(f"âœ… è·å–æ•°æ®é›†ä¿¡æ¯æˆåŠŸ: {dataset_info.get('display_name')}")
                print(f"  æè¿°: {dataset_info.get('description', 'N/A')[:50]}...")
                print(f"  æ ·æœ¬æ•°: {dataset_info.get('total_samples', 'N/A')}")
                return True
            else:
                print(f"âŒ è·å–æ•°æ®é›†ä¿¡æ¯å¤±è´¥")
                return False
                
        except Exception as e:
            print(f"âŒ æµ‹è¯•è·å–æ•°æ®é›†ä¿¡æ¯å¤±è´¥: {e}")
            return False
    
    async def test_natural_language_query(self):
        """æµ‹è¯•è‡ªç„¶è¯­è¨€æŸ¥è¯¢åŠŸèƒ½"""
        print("\nğŸ” æµ‹è¯•è‡ªç„¶è¯­è¨€æŸ¥è¯¢åŠŸèƒ½...")
        
        queries = [
            "æ‰¾ä¸€äº›ä¸­æ–‡æ–‡æœ¬åˆ†ç±»çš„æ•°æ®é›†",
            "æˆ‘éœ€è¦æƒ…æ„Ÿåˆ†æçš„æ•°æ®",
            "æœ‰æ²¡æœ‰å‘½åå®ä½“è¯†åˆ«çš„æ•°æ®é›†"
        ]
        
        results = []
        
        for query in queries:
            try:
                result = await self.handlers['query_dataset'].handle({
                    "query": query,
                    "limit": 3
                })
                
                success = result.get("success", False)
                datasets = result.get("datasets", [])
                
                print(f"  æŸ¥è¯¢: '{query}'")
                print(f"    ç»“æœ: {'âœ…' if success else 'âŒ'} ({len(datasets)} ä¸ªæ•°æ®é›†)")
                
                if datasets:
                    for i, dataset in enumerate(datasets[:2], 1):
                        print(f"    {i}. {dataset.get('display_name', dataset.get('name'))}")
                
                results.append(success)
                
            except Exception as e:
                print(f"  æŸ¥è¯¢ '{query}': âŒ é”™è¯¯: {e}")
                results.append(False)
        
        return any(results)  # è‡³å°‘æœ‰ä¸€ä¸ªæŸ¥è¯¢æˆåŠŸ
    
    async def test_siliconflow_integration(self):
        """æµ‹è¯•ç¡…åŸºæµåŠ¨APIé›†æˆ"""
        print("\nğŸ” æµ‹è¯•ç¡…åŸºæµåŠ¨APIé›†æˆ...")
        
        try:
            # æ£€æŸ¥é…ç½®
            config_file = Path("config.json")
            if not config_file.exists():
                print("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
                return False
            
            with open(config_file, 'r', encoding='utf-8') as f:
                config_data = json.load(f)
                siliconflow_config = config_data.get('siliconflow', {})
            
            if not siliconflow_config.get('enabled'):
                print("âŒ ç¡…åŸºæµåŠ¨APIæœªå¯ç”¨")
                return False
            
            api_key = siliconflow_config.get('api_key')
            api_url = siliconflow_config.get('api_url')
            
            print(f"âœ… ç¡…åŸºæµåŠ¨APIé…ç½®æ­£ç¡®")
            print(f"  API URL: {api_url}")
            print(f"  API Key: {api_key[:10]}...{api_key[-10:] if api_key else 'None'}")
            
            # è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„APIè°ƒç”¨æµ‹è¯•
            # ç”±äºéœ€è¦ç½‘ç»œè¯·æ±‚ï¼Œæš‚æ—¶åªéªŒè¯é…ç½®
            
            return True
            
        except Exception as e:
            print(f"âŒ ç¡…åŸºæµåŠ¨APIé›†æˆæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def cleanup(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        try:
            if self.db_service:
                await self.db_service.close()
            print("âœ… èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            print(f"âŒ æ¸…ç†å¤±è´¥: {e}")
    
    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹æ•°æ®é›†æŸ¥è¯¢åŠŸèƒ½éªŒè¯æµ‹è¯•...")
        
        # åˆå§‹åŒ–
        if not await self.setup():
            return False
        
        try:
            # æ·»åŠ æµ‹è¯•æ•°æ®
            await self.add_test_datasets()
            
            # è¿è¡Œæµ‹è¯•
            tests = [
                ("ç¡…åŸºæµåŠ¨APIé›†æˆ", self.test_siliconflow_integration()),
                ("åˆ—å‡ºæ•°æ®é›†", self.test_list_datasets()),
                ("è·å–æ•°æ®é›†ä¿¡æ¯", self.test_dataset_info()),
                ("è‡ªç„¶è¯­è¨€æŸ¥è¯¢", self.test_natural_language_query())
            ]
            
            results = {}
            
            for test_name, test_coro in tests:
                try:
                    result = await test_coro
                    results[test_name] = result
                except Exception as e:
                    print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥: {e}")
                    results[test_name] = False
            
            # è¾“å‡ºæµ‹è¯•ç»“æœæ‘˜è¦
            print("\nğŸ“Š æ•°æ®é›†æŸ¥è¯¢åŠŸèƒ½éªŒè¯ç»“æœæ‘˜è¦:")
            print("=" * 50)
            
            passed = 0
            total = len(results)
            
            for test_name, result in results.items():
                status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
                print(f"  {test_name}: {status}")
                if result:
                    passed += 1
            
            print(f"\næ€»è®¡: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
            
            if passed == total:
                print("ğŸ‰ æ‰€æœ‰æ•°æ®é›†æŸ¥è¯¢åŠŸèƒ½éªŒè¯éƒ½é€šè¿‡äº†ï¼")
                return True
            else:
                print(f"âš ï¸  æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")
                return False
                
        finally:
            await self.cleanup()


async def main():
    """ä¸»å‡½æ•°"""
    tester = DatasetQueryTester()
    success = await tester.run_all_tests()
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    asyncio.run(main())